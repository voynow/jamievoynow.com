data = """Sun Apr 13 2025: Even if I exited @ $millions I'd still be shipping on the TL, and building my brand. This is why I cannot be stopped
Sun Apr 13 2025: people hallucinate just as much as (if not more than) LLMs, but yall ain't ready for that conversation
Sat Apr 12 2025: @willccbb yep seems so simple - what took them so long to ship this?
Sat Apr 12 2025: @levelsio this extrapolation is hilarious https://t.co/wJdGkw3bpd
Sat Apr 12 2025: How to Vibe Code without getting lost in the sauce My take on the stages of Vibe Coding as software products evolve from demo to production Demo: Pure Vibes Get the demo out as fast as possible despite the grossness of the code. Validate quickly. A landing page, a notebook, or
Fri Apr 11 2025: @todor_m_markov these guys just made up the word amicus and think they are going to get away with it?
Fri Apr 11 2025: @willccbb its simply a distilled reasoning quantized pruned sparse model whats so confusing?
Fri Apr 11 2025: @yacineMTB how come if I were to apply through X I can't just seamlessly apply with my X profile? This IS my resume. Idk why it's asking for my linkedin
Thu Apr 10 2025: 100 days into 2025, 517 commits deep, speedrunning to burnout AMA https://t.co/Pxhx2y9WZr
Tue Apr 08 2025: @FJ000RD yeah from a strategy perspective this is a killer move for them but obv we, the tech community, prefer open source/model provider agnostic
Tue Apr 08 2025: @hnshah theres so much competition in this space too wonder how it will play out
Tue Apr 08 2025: To be fair, OpenAI has pointed out to me that they do support generic completion uploads (as long as they follow the openai format). but I am generally skeptical of building inside a platform that favors their own patterns when sooo many alternatives exist. Anyway try it yourself
Tue Apr 08 2025: @defjosiah OK I'll admit that I may have overreacted a bit without fully researching. But I will say that I'd generally prefer a generic solution that doesnt explicitly favor openai patterns. Thanks for pointing this out, and I am excited to try it for myself, but I am skeptical
Tue Apr 08 2025: @OpenAIDevs Evals should not lock you into a single LLM provider. https://t.co/uwoi4M5P2l
Tue Apr 08 2025: I'm a huge fan of OpenAI, but this is bad. Evals that lock you into a single LLM provider defeat the entire purpose of an evaluation platform. In a world where LLM benchmarks and leaderboards are being gamed and increasingly meaningless, running your own evals (across models) on
Mon Apr 07 2025: cementing my bloodline in the AI hype cycle https://t.co/LTyPArKDeW
Mon Apr 07 2025: Stressin about stocks? Here's my expert 3-step framework ü§Øüëá (1) stop being an emotional investor (2) grow a spine (3) seriously stop being emotional
Sun Apr 06 2025: @yacineMTB saving money is betting that your future self won't be better than your current self, and that's bs
Sun Apr 06 2025: @signulll don't you think that the other side is getting in on the fomo too? sellers can get away with raising prices even before underlying components/goods increase in price. I wonder who is winning on this trade rn
Sat Apr 05 2025: The ‚ÄúRAG is dead‚Äù people are wrong RAG isn't about solving for a finite context window, it's about filtering for signal from a noisy dataset. No matter how big and powerful your context window gets, removing junk data from the input will always improve performance
Sat Apr 05 2025: @willccbb great to see that meta is continuing to push the frontier of what's possible. incredible!
Sat Apr 05 2025: Uhhhhhhh something is wrong with my Cursor chat https://t.co/M8zsvGbZB7
Sat Apr 05 2025: I'm constantly cycling through &gt; need to lock in harder, skipping the gym &gt; i'm depressed and out of shape &gt; gotta gym to get back into shape &gt; oh shit depression cured &gt; need to lock in harder, skipping the gym &gt; repeat currently in my ‚Äúoh shit depression cured‚Äù arc
Thu Apr 03 2025: We burned through over 400M tokens on the JFK files last month..... holy moly https://t.co/gqtCQeS0nP
Thu Apr 03 2025: @levelsio this will always happen, the new infrastructure built today will always be more modern than legacy infrastructure that was previously ‚Äúmodern‚Äù. Look at the NYC subway for a great example, or the empire state building
Tue Apr 01 2025: I yearn for the rush of virality again https://t.co/IcbNcatAjb
Sun Mar 30 2025: GM team and happy Sunday. Woke up thinking about B2B SaaS üò§üò§ https://t.co/iZljlvZa9J
Sat Mar 29 2025: Java is actually insane. Go, Rust, Python exist, yet your code still looks like ‚ÄúAbstractEnterpriseBeanFactory‚Äù? Do you hate shipping fast, or just hate yourself?
Sat Mar 29 2025: the best vibe coders are so good that you don't even know they are vibe coding, they walk among us
Sat Mar 29 2025: @yacineMTB RL is a lot of nooancer ideas imo. A lot of it is just traditional ML with a few extra steps
Fri Mar 28 2025: @elonmusk @xai @X am i reading this correctly? XAI acquired X? üòØ
Fri Mar 28 2025: brb pivoting to consulting, DMs are open https://t.co/Tv58LrHMbj
Thu Mar 27 2025: @jiratickets genuine question - {insert bait} love this format i might have to steal it
Thu Mar 27 2025: @ludwigABAP this guy is talking his own book so hard that's crazy
Wed Mar 26 2025: Just updated ChatWithJFKFiles what do you guys think? https://t.co/QujcynweQL
Tue Mar 25 2025: @unusual_whales Shout out to @howardlutnick for calling it first
Tue Mar 25 2025: THEY DELETED ALL OF MY DRAFTS üò≠ Just imagine this is a banger from my drafts and engage accordingly
Sat Mar 22 2025: @tunahorse21 at chilis can't talk rn https://t.co/qdHpq8znUh
Thu Mar 20 2025: The aftermath ... no shot this number is real right?? https://t.co/JlFQ9YcjwK  {{over 15k users in two days}}
Wed Mar 19 2025: ChatWithJFKFiles was just the beginning. Y'all are NOT ready for what's next https://t.co/DOzbbC7tuz
Wed Mar 19 2025: 100+ stars on Github is worth 100k followers on twitter. This is the conversation rate I don't make the rules. https://t.co/SJt4q27rkD
Wed Mar 19 2025: New Feature Drop! Citation Summarization on ChatWithJFKFiles Citations are critical for confidence in any RAG application. Diving into the raw underlying documents is key to validating the information being provided by a chat system. One of the biggest issues with the initial https://t.co/WwoqOqwzD1
Wed Mar 19 2025: Looks like there was an outage. Should be fixed now. Anyone who experienced error messages please refresh and let me know if the issue persists.
Wed Mar 19 2025: Big News: All new documents have now been indexed on chatwithjfkfiles,com So far today 2.5 thousand users have burned through almost 50 million tokens. insane man. https://t.co/nuWc5rbimz
Tue Mar 18 2025: HOST http://chatwithjfkfiles,com https://t.co/ECIZawzbaB
Tue Mar 18 2025: New documents hot off the presses! Live now on chatwithjfkfiles,com https://t.co/4EhgnZH3wO
Tue Mar 18 2025: The consequences of shipping too hard https://t.co/C6rvjXDqbt
Tue Mar 18 2025: @carlo_5518 TY! i made the decision to make it entirely the new batch (I have the old batch but turned it off for now) thoughts?
Tue Mar 18 2025: @amuse I built a tool just for you guys to inspect the files, check it out: https://t.co/mjZ6XHT4RH
Tue Mar 18 2025: Annnnd if any of you sugar mommies / daddies want to fund me, I do pay for this out of my own pocket: https://t.co/GwaoqYAVZF
Tue Mar 18 2025: Current I have indexed 30% of the documents. Will continue indexing as the night goes on. stay tuned
Tue Mar 18 2025: Fully open source for the win https://t.co/TWfnJPDAEU
Tue Mar 18 2025: RE-LAUNCHING Chat With JFK Files . com Updated TODAY with new documents from March 18th 2025. https://t.co/hXqgs754Aw
Tue Mar 18 2025: GM today is going to be a YUUGGE day https://t.co/o9DpTnSQyN
Mon Mar 17 2025: @rankintweets @joinwarp Saturdays &amp; Mondays ‚úÖ https://t.co/ZCypVqr3wk
Sun Mar 16 2025: I'm using my .env as a database and god I've never felt so free https://t.co/A6YPBXNpmZ
Wed Mar 12 2025: @0xKyon @levelsio hating on levels again https://t.co/dQD0c5ziMv
Mon Mar 10 2025: you onboard as CTO to an early stage startup and come to find that their codebase is written almost entirely in Java, WYD?
Tue Mar 04 2025: Folks - If you are reading this, that means Jamie is currently taking a break from X/Twitter. We appreciate your patience while he is (hopefully) touching grass. Assume that any posts from Jamie in the near future are scheduled. Best, Jamie's Team
Sat Mar 01 2025: Quick rant on why virality sucks Not all followers are created equal. Like everything else, your follower network follows the Pareto principle: 80% of the value comes from the top 20% of connections (although realistically its the top 5%) These are the people who engage with
Sat Mar 01 2025: @skydotcs I literally do this and it works wonders - my coworkers hate me
Thu Feb 27 2025: You are one GPT wrapper away from financial freedom what are you waiting for?
Wed Feb 26 2025: steak and eggs, brunch of champions https://t.co/sQOJzqqhKp
Mon Feb 24 2025: @abacaj we knew gpt5 was going to be underwhelming when they didnt release it in 2024 tbh
Mon Feb 24 2025: @mwfowlie Dude yes FAANG eng GroupThink is not helpful for 99.9% of use cases. Zuck famously didn't give a shit about scale until he hit scaling issues, instead he just shipped And yeah message queues are inherently not real time lol
Sun Feb 23 2025: This take is so bad. I built a viral chat app that scaled to thousands of users and broke EVERY rule Alex claims is required for a "well-designed" application. &gt;No, you don't need RabbitMQ &gt;No, you don't need microservices &gt;No, you don't need to design for OpenAI rate limits
Sun Feb 23 2025: @vivek_naskar i feel like 80% of these are irrelevant though
Fri Feb 21 2025: For $40, you could spin up 3-5 apps on DigitalOcean in a weekend No one cares about multi-leader replication or B-Trees. The only thing that really matters is good product and distribution https://t.co/lMvwvUxuVI
Thu Feb 20 2025: @paulg "If Zuck and Alex Wang did it I need to do it too!" not a good idea
Thu Feb 20 2025: Book is mid. Stop larping and go build something https://t.co/ZPqN0S4P07
Thu Feb 20 2025: @signulll @0xluffyb seniority in BigCo is derived from loyalty not ability it seems
Wed Feb 19 2025: @TheRoyalSerf the trump haircut back when it was in style
Wed Feb 19 2025: The software job market is coming back I can smell it in the air
Mon Feb 17 2025: SWEs hate this one trick: forget the DB just ask claude to make up the data on the spot
Mon Feb 17 2025: Starting with something simple: Generating Readmes &gt;&gt;&gt; pip install turbo-docs &gt;&gt;&gt; turbo-docs --readme Now what should I build next? ü§î https://t.co/e97rBlNDAO
Mon Feb 17 2025: OpenAI clearly has a 'break glass in case of competition' model vault. Remember DeepSeek? O3 + Deep Research seemed to drop at the perfect time (now DS is irrelevant) If Grok3 is more than just a meme we will get 4.5 next week
Mon Feb 17 2025: I've had the urge for months/years to build an AI devtools company (no not a VScode fork). There are 100 use-cases in doc generation alone. Chat what do we think?
Sun Feb 16 2025: Today I set out on a mission to see how fast I could go from idea to launch. And 10 hours later here it is: ship fast or die . com A leaderboard celebrating builders who ship - Ship faster and rank higher - Less code ranks higher than more code - GitHub stars give you a boost https://t.co/5cH4FEiKS7
Sat Feb 15 2025: You add me to your repo and my first commit: &gt;33 files changed &gt;7k LoC added &gt; git commit -m "cool new feature" wyd in this scenario? https://t.co/bNFTDsbhGb
Sat Feb 15 2025: Early generative models had this raw, dreamlike quality - unfortunately for the sake of "accuracy" this seems to be lost today https://t.co/OIeKVWuKZJ
Wed Feb 12 2025: @jxnlco and o3 is just 4o with a for loop its for loops all the way down
Wed Feb 12 2025: X/twitter is not a posting app, its a DMing app. Making friends &gt;&gt;&gt;&gt; shouting into the void. Leveraging this correctly will make or break your experience here
Mon Feb 10 2025: Credibility in online communities is the only moat in the post scarcity world
Sun Feb 09 2025: if betting on the coin toss is bad, then what do we have to say about betting on the gatorade shower? üíÄüíÄ https://t.co/gepN1przYb
Sun Feb 09 2025: maybe if you didnt waste your days fine-tuning you would actually ship something. Sorry ML researchooors distribution is the only thing that matters in the post cursor/o1/deepseek world
Sat Feb 08 2025: Twitter/X was hard for a while. Growth was VERY slowly. But once I started being my real self and connecting with real friends, growth happened organically as a side effect. In retrospect, investing time here has been one of my best investments. This platform has helped me in so
Fri Feb 07 2025: just going to leave this here ......... https://t.co/qchTwSs8gY
Fri Feb 07 2025: whichever PM at vscode decided to put delete file next to rename deserves to be fired frfr https://t.co/sXTKjK7jWa
Thu Feb 06 2025: Dear algorithm, please teleport me to quant / algo twitter (temporarily) üôè
Wed Feb 05 2025: programming without copilot makes my brain hurt‚Ä¶ lowkey ai tools are making me dumber‚Ä¶ we're so cooked
Wed Feb 05 2025: gmgm I joined X/twitter two years ago today https://t.co/EpeIRaeiIc
Tue Feb 04 2025: @amasad So you just hallucinate every API / all database queries?
Mon Feb 03 2025: At the risk of sounding annoying - I need to post this one last time. This guy is straight up plagiarizing my work (for the second time) - copying my GitHub, listing my employer in his bio - zero effort to hide it. He's scammed people out of thousands, and now I'm the one https://t.co/juX1h1cD4b
Sun Feb 02 2025: LAUNCHING üö® Crush Your Race I've built v1 of the world's first ai-powered running coach: ‚úîÔ∏è Generate a custom-tailored running plan based on your Strava data, all in one click. ‚úîÔ∏è Get hyper-personalized adjustments live as you train, so you can run smarter, not harder. Link https://t.co/SiJZp61Me8
Sun Feb 02 2025: I have a suspicion that this is bigger than rate limits. openai._base_client:_base_client.py:1653 Retrying request to /chat/completions in 0.792889 seconds ... APIConnectionError('Connection error.') Has anyone encountered this before? It seems that the error is intermittent
Sun Feb 02 2025: @OpenAI I'm already Tier 3, which is insane, but 800,000 TPM for 4o just isnt enough.....
Sun Feb 02 2025: Can someone please help me get a higher rate limit @OpenAI üôèüôèüôè INFO openai._base_client:_base_client.py:1653 Retrying request to /chat/completions in 0.958383 seconds INFO openai._base_client:_base_client.py:1653 Retrying request to /chat/completions in 1.741543
Wed Jan 29 2025: First million impression week AMA https://t.co/LmnSU41RLm
Tue Jan 28 2025: This person is impersonating me and scamming with crypto, tpot do your thing (report this guy) @ ntdillon https://t.co/XkAtlF2JiC
Tue Jan 28 2025: @ludwigABAP researchooors should focus on creating value
Tue Jan 28 2025: Just woke up from a dream about twitter. it's over bros i need a detox
Sun Jan 26 2025: the algo is cooking right now my tl is like a work of art
Sun Jan 26 2025: 24 isnt enough. I need more hours in a day. Who's building this???
Sat Jan 25 2025: @patternedchair @atensnut Definitely will fix for v2!
Sat Jan 25 2025: @ccurtis584 @atensnut yep its rag! Using: https://t.co/2k8M6EGuBE
Sat Jan 25 2025: @atensnut I literally built this https://chatwithjfkfiles.com
Sat Jan 25 2025: Almost doubled my followers this week - seems like a good time to introduce myself: Hi, I'm Jamie Voynow ("Voy - now"). By day, I'm a machine learning engineer on Wall Street. By night, I'm a founder. Some of you might know me as the chatwithjfkfiles(dot)com guy, but for the past few months, I've been building something entirely different at the intersection of running and AI (big launch next week).\nA quick timeline of the journey so far:\n2017 ‚Äî Started college, dropped physics, switched to CS\n2020 ‚Äî Got into ML research, received an NSF grant\n2021 ‚Äî Worked on ballistic missile defense as a Data Scientist\n2022 ‚Äî Ran a marathon\n2023 ‚Äî ChatGPT changed the world\n2024 ‚Äî Moved to NYC, joined an amazing team, doubled my salary\n2025 ‚Äî Built my first viral app (and it's still January)\nThis year is about building, learning, and connecting. My DMs are always open - let's chat.\nStill just getting started,\nJamie
Sat Jan 25 2025: @swyx it's easy to sit back and critique this but this is the correct way to be entrepreneurial by taking many bets
Fri Jan 24 2025: My favorite outcome from going viral overnight is that 27+ people liked my code enough to save it for later. Proud engineer moment. https://t.co/pZAC4I8K4r
Fri Jan 24 2025: @_401_Nick True yeah there are a ton of optimizations that could be made if we wanted to improve this thing - for instance my chunking strategy was not very sophisticated - many things like this I skipped over for the sake of dev velocity
Fri Jan 24 2025: We've burned through 7.5 million tokens in &lt;12h üëÄ https://t.co/Q36nVpbwpY
Fri Jan 24 2025: @scatteredbrainn theoretically it shouldn't be very good at summarizing, but this looks decent to me
Thu Jan 23 2025: @kdotmixalot just some nextjs. nothing fancy. used cursor to help design it
Thu Jan 23 2025: looks like yall are having too much fun and took down my server THANKS
Thu Jan 23 2025: @SterlingCooley updating as they come - will add the new ones when they drop
Thu Jan 23 2025: @n4v1g8 i was thinking about the idea all day it just exploded out of me this afternoon hahahaha
Thu Jan 23 2025: @TechMemeKing I couldn't get the idea out of my head I had to build it, thanks bro
Thu Jan 23 2025: @joeybab3 yessir saw the opportunity and went for it
Thu Jan 23 2025: @Aizkmusic Just trying to follow in your footsteps bro
Thu Jan 23 2025: LAUNCHING Chat With JFK Files . com Using documents from the JFK Assassination National Archive Records (linked below) https://t.co/FjNIvxTBqP {{this got almost 500k impressions}}
Tue Jan 21 2025: @IterIntellectus I will live to 150 years old and build an empire
Sat Jan 18 2025: party trick: solving leetcode hards while intoxicated
Fri Jan 17 2025: If you're not using o1, you're missing out big time. This is your sign to reconsider. I was a hater at first, bc theres a bit of a learning curve (see "o1-skill-issue" linked in the comments) - but for massive/messy context its sota for sure https://t.co/Cafe6Q7m5I
Wed Jan 15 2025: Onboarding beta users ‚úÖ‚úÖ‚úÖ Jamie: 1 Deadlines: 0 https://t.co/Xpyhf1TLzt"""


article = """Chat Apps > MCP, Agents, Etc
If you spend enough time on Twitter, you might think that "RAG is dead" or that "chat apps are cringe" and that agentic systems, model context protocol MCP, and other bleeding-edge ideas are the only things that matter. The reality is that Chat applications still make up 95% of successful production LLM projects. And while long term I am bullish on agents, my job is to create value today.
This article is my raw, unfiltered playbook on how I build and scale chat apps fast by minimizing complexity, and getting real products into the hands of users ASAP.
Why You Should Believe Me
You probably know me as the Chat with the JFK Files guy. The day those files dropped, I built and shipped the app from 0 to 1 in just 4 hours. It took off fast: racking up 1M+ views on Twitter, tens of thousands of users, and just last week alone, it processed 83,000+ user events.
Google Analytics from this week
What most people don't know is that I've been building chat apps like this for years - it took years of preparation to be able to ship an effective chat app in an afternoon. By now, I've fine-tuned a brutally simple, radically anti-complex strategy that gets the job done. Some of it may go against intuition, but it works - serving thousands of users this week alone.
Basic Requirements
This is the quick and dirty way to build a chat app. And thats for the best. Odds are, your app won't be handling enterprise-scale traffic right away, so the goal is to write the least amount of code necessary to get a working product in front of users.
At minimum you will need the following
OCR: If needed, convert documents into text
Chunking: Converting text into bite-sized LLM-consumable pieces
Embeddings: Converting chunks into vectors
Vector DB: System for storing and retrieving embeddings/chunks
Language Model: LLM for answering Qs based on retrieved chunks
Frontend/Backend/Infra: The apps and compute required to get the job done
That's it. There are plenty of other optimizations that you could spend days or weeks on, but imo this is all you need to ship.
Don't Think, Just Ship
I feel very strongly that building fast and dirty is far more important than obsessing over details early on. No one cares about how good your ideas are if they never see the light of day. You won't build a following by talking about building - rather then tell people that you are legit, show them (by shipping). The same goes for stakeholders and customers: no one will praise you until they can actually use what you've built. So stop thinking and build that demo.
Critics will argue that once you find PMF and scale, you've f*cked yourself with bad architecture and tech debt; My counter: I'd rather deal with the consequences of suboptimal architecture then never ship at all.
OCR (If Applicable)
OK you have the documents, but what about converting them to useable text? OCR is the go-to solution, and frankly I don't have strong opinions on how you do it.
If your workload is small (<1k files), you could just rip it locally. I used pytesseract locally simply because I had some code laying around.
If your workload is large, if you want convenience, if you have cash to burn: use a cloud OCR service (Azure OCR, https://chunkr.ai/, etc)
Slight tangent: Gemini is basically SOTA in OCR in terms of both cost and accuracy (https://www.sergey.fyi/articles/gemini-flash-2). As LLMs improve, I expect this gap to widen where Gemini and co become the standard for fast, cheap, accurate OCR. I have yet to test this personally, but its worth exploring.
Chunking
One of my favorite topics! Here's a quick story to illustrate my opinion.
A coworker once dumped a failing project on me. The app barely worked: it was too expensive and way too slow. The problem? An over-engineered chunking strategy (using a sentence-level LLM classifier with max voting). Being me, I decided to do something quite radical to test my intuition. I threw out the old chunker and replaced it with dumb_fast_chunker, which split on newline characters and merged small chunks. No fancy classifiers, no extra steps. And to everyones surprise, our evals didn't budge. To this day dumb_fast_chunker is used in production 1000s of times per year.
The takeaway? Over-optimizing on chinking early on is a waste of time. Do the simple thing, build evals, and be data driven about further optimization.
Embeddings/Vector Database
Do whatever you gotta do to make your vector operations fast. Contrary to popular belief, at small-medium scale you can do this entirely in memory.
Generate embeddings: Just use OpenAI and don't question it (more on this later)
Store your embeddings: Create a Polars DF containing embeddings, chunks, metadata and use polars.DataFrame.write_parquet to create your ‚ÄúDB‚Äù
Retrieve embeddings: Read parquet file (possibly using functools.lru_cache) and use Numpy to calculate cosine similarity
Yes, the minimal approach is radical, but its unbelievably fast and simple for most workloads. Believe it or not, this is exactly how the first release of ChatWithJFKFiles was designed.
Okay okay - this does come with a huge caveat: for large workloads, you'll need a real vector DB to offload memory and compute from your server. Here I would recommend using Pinecone or equivalent, I've had no problems using Pinecone free tier.
Language Models
You need an LLM, but don't overthink this.
Benchmarks and performance metrics don't matter if the model fails under production workloads. Nothing beats OpenAI models in terms of performance and reliability - especially under workloads of high concurrency.
Rate limits are often cited as an issue, but OpenAI scales usage limits for its paying customers. For instance, my GPT-4o limit is currently sitting at 50M tokens per minute. If I ever hit that kind of load, we've got bigger problems (time to raise seed round).
Frontend, Backend, Infra
This is mostly personal preference - except for python, which is objectively the best language for AI development.
Frontend: I use Next.js + Vercel because it abstracts away the annoying and non differentiated parts of development (CICD, hosting, logging, etc). Sorry Vercel haters please forgive me.
Backend: Fast API & Digital Ocean App Platform > AWS. DO is cheaper, simpler, and again has built in CICD which is massive. In the event that your product goes viral, DO App Platform makes scaling very easy (more on this later).
These are the tools I use, but feel free to use what lets you ship the fastest.
Operating at Scale
This architecture actually scales well - but of course simplicity comes at a cost.
Your backend won't be able to handle major load on a single node. The fix? If you are using digital ocean, you can easily scale up the number of containers you are running.
Yes, it'll get expensive in the short term. But if your app is going viral, you only need to stomach the costs for a day or two. If traffic stays high, congrats - you have a real product. Monetize ASAP. Hire engineers. Maybe raise VC.
Stop worrying about costs. Building credibility is more valuable than a $20 bill from OpenAI + a $20 bill from digital ocean.
What Now
I'm not sure if I'll keep launching new released of JFK files or similar projects. While I am bullish on chat apps, something tells me its time to take on bigger challenges.
That said, ChatWithJFKFiles isn't going anywhere, and I will continue sharing what I've learned. If you want to chat, HMU! I can't promise that I will have time for everyone, but I'm always looking to connect with like-minded people.
And yeah, at the risk of sounding cringe, I am open to business opportunities. Need help building a chat app for your business? lets talk"""


def get_data() -> str:
    return data


def get_article() -> list[str]:
    return article
